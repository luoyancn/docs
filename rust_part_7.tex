\section{多线程}
Rust也同样支持常见的并行和并发操作，也同样分为进程，线程以及消息通信等等。

\subsection{线程}
Rust的线程操作必须使用闭包完成。在之前看到的闭包当中，通常采用的都是有参的闭包，
而在Rust的线程操作当中，则经常会遇到无参数的闭包；Rust的线程使用thread::spawn函数
进行实现：
\begin{code-block}{rust}
use std::thread;
use std::time::Duration;
fn main() {
    thread::spawn(|| {
        for i in 1..10 {
            println!("hi number {} from the spawned thread!", i);
            thread::sleep(Duration::from_millis(1));
        }
    });
    for i in 1..5 {
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(1));
    }
}
\end{code-block}
和其他语言的线程概念一样，当主线程结束时，所有的线程都会被终止。因此上述代码当中，
子线程（spawn）无法将所有的循环执行完成。为了达成所有进/线程执行完成之后才退出主
进/线程的目的，和其他的开发语言相同，需要在主进程当中调用join函数：
\begin{code-block}{rust}
fn main() {
    let handle = thread::spawn(|| {
        for i in 1..10 {
            println!("hi number {} from the spawned thread!", i);
            thread::sleep(Duration::from_millis(1));
        }
    });
    for i in 1..5 {
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(1));
    }
    handle.join().unwrap();
}
\end{code-block}
Thread::spawn的返回值是JoinHandle，是一个拥有所有权的值，当对其调用join方法时，
它会等待对应线程结束；而join的返回值是一个Result，可以按照之前介绍的方式进行处理。
同时，Join函数是一个阻塞式函数，只有当该函数运行结束之后，才会继续进行后续的操作。

多数情况下，Rust的线程不可能只会在内部运行，而和外部没有数据交互。但是，如果我们
直接使用外部数据，则会出现错误，比如下方的代码：
\begin{code-block}{rust}
fn main() {
    let v = vec![1, 2, 3];
    let handle = thread::spawn(|| {
        println!("Here's a vector: {:?}", v);
    });
    handle.join().unwrap();
}
\end{code-block}
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{rust_thread_out_params.png}
  \caption{试图访问线程外部资源}
  \label{fig:rust_thread_out_params}
\end{figure}
线程使用的是闭包，从闭包的定义来说，是可以捕获并使用外部变量和数据的；但是，Rust
不知道这个线程到底会运行多长时间，因此无法知道对外部变量的引用是否一直有效，比如
下方的代码：
\begin{code-block}{rust}
fn main() {
    let v = vec![1, 2, 3];
    let handle = thread::spawn(|| {
        println!("Here's a vector: {:?}", v);
    });
    drop(v);
    handle.join().unwrap();
}
\end{code-block}
启动线程的同时，立即将v进行丢弃，线程内部无法知道v在运行阶段是否继续有效，就会
出现错误，因此，如果在线程当中使用默认的闭包模式，则无法对应的闭包是无法捕获以及
使用外部的变量和数据的。此时，则需要使用move闭包进行替换，即强制闭包获取外部变量
的所有权，而不是由Rust进行借用推断。但是需要注意，一旦使用move之后，在线程之外，
变量将无法再进行使用：
\begin{code-block}{rust}
fn main() {
    let v = vec![1, 2, 3];
    let handle = thread::spawn(move || {
        println!("Here's a vector: {:?}", v);
    });
    // 下方代码无法再进行执行
    // println!("{:?}", v);
    handle.join().unwrap();
}
\end{code-block}

\subsection{消息通信和消息传递}
每个线程做自己的事情，但是，不管什么编程语言，都需要考虑线程之间的数据交互问题。
Rust向Golang进行了学习，使用通信替换共享内存，来进行线程之间的数据传输。同样的，
Rust当中用于消息传递并发的主要工具是通道，该概念和Golang的通道概念相同。Rust的通道
分为2个角色：发送者和接收者，发送者发送消息，接收者接收消息，当发送者或者接收者任一
被丢弃时，则对应的通道被视为关闭。

Rust的通道采用mpsc::channel函数实现，mpsc表示多个生产者，单个消费者，因此，Rust
标准库实现通道的方式意味着一个通道可以有多个产生值的发送（sending）端，但只能有
一个消费这些值的接收（receiving）端。通道的实现示例如下：
\begin{code-block}{rust}
use std::sync::mpsc;

fn main() {
    let (sender, recevier) = mpsc::channel();
}
\end{code-block}
其中，函数的第一个返回值为发送者，第二个参数为接收者。使用通道发送数据通信的示例
如下：
\begin{code-block}{rust}
use std::sync::mpsc;
use std::thread;

fn main() {
    let (sender, recevier) = mpsc::channel();

    thread::spawn(move || {
        let val = "lucifer".to_string();

        match sender.send(val) {
            Ok(_) => println!("Send success"),
            Err(error) => println!("Send failed :{:?}", error),
        }
    });

    let res = match recevier.recv() {
        Ok(s) => s,
        Err(error) => {
            println!("Cannot recevie anything from sender: {:?}", error);
            "".to_string()
        }
    };

    println!("The result of channel is {}", res);
}
\end{code-block}
接收者接收消息有2种模式：默认的recv是阻塞式，返回一个Result<T, E>，当通道关闭时，
将返回Result当中的Error；而try\_recv是非阻塞式，同样是返回一个Result<T, E>，但是，
Result当中的Error表示没有接收到任何消息，可以使用for循环进行反复的尝试读取操作。
另外需要注意的是，Send函数会改变变量的所有权，当该函数执行之后，被发送的消息
（变量）将无法再使用。

但是，通道可以反复使用，而且和Golang的类似，Rust的通道也是可以进行迭代的，特别
是在接收消息时，通常采用for循环进行操作，减少了错误处理的代码，使得代码更具可读性：
\begin{code-block}{rust}
use std::sync::mpsc;
use std::thread;

fn main() {
    let (sender, recevier) = mpsc::channel();

    let handler = thread::spawn(move || {
        let vals = vec!["lucifer", "titans", "garuda"];
        for val in vals {
            match sender.send(val) {
                Ok(_) => println!("Send success"),
                Err(error) => println!("Send failed :{:?}", error),
            }
        }
    });

    for msg in recevier {
        println!("The msg is {}", msg);
    }

    match handler.join() {
        Err(error) => println!("Error{:?}", error),
        _ => (),
    }
}
\end{code-block}

同样的，由于Rust的通道默认是多生产者/单消费者，因此，可以通过多个发送端向单个接
收端发送消息。实际使用当中的多个发送端，则通常是某个发送端的克隆对象，如下：
\begin{code-block}{rust}
use std::sync::mpsc;
use std::thread;

fn main() {
    let (sender, recevier) = mpsc::channel();
    let sender_copy = sender.clone();

    let handler = thread::spawn(move || {
        let vals = vec!["lucifer", "titans", "garuda"];

        for val in vals {
            match sender.send(val) {
                Ok(_) => println!("Send success"),
                Err(error) => println!("Send failed :{:?}", error),
            }
        }
    });
    let handler_copy = thread::spawn(move || {
        let vals = vec!["zhangjl", "luoyan", "zhangzz"];

        for val in vals {
            match sender_copy.send(val) {
                Err(error) => println!("Send failed :{:?}", error),
                _ => (),
            }
        }
    });
    for msg in recevier {
        println!("The msg is {}", msg);
    }
    match handler_copy.join() {
        Err(error) => println!("Error{:?}", error),
        _ => (),
    }
    match handler.join() {
        Err(error) => println!("Error{:?}", error),
        _ => (),
    }
}
\end{code-block}

\subsection{共享状态}
在其他语言当中，有些特殊的场景，还是必须使用原有的线程并发概念——锁——来进行资源的
访问/读写控制。Rust当中同样存在锁，比较常见的就是互斥锁（互斥器，Mutex）以及原子
计数器（Arc）。在基本的操作上，互斥锁的使用和其他语言当中没有太大的区别：
\begin{code-block}{rust}
use std::sync::Mutex;
fn main() {
    let m = Mutex::new(5);
    {
        let mut num = m.lock().unwrap();
        *num = 6;
    }
    println!("m = {:?}", m);
}
\end{code-block}
注意，上述代码如果将内部大括号去除，则运行结束之后，m的状态还是锁定状态；但是，
有大括号，则表示大括号内部的段是一个有效的生命周期，当该生命周期结束之后，互斥
锁将自动释放。一旦获取了锁，就可以将返回值（在这里是num）视为一个其内部数据的
\colorblock{可变引用}。类型系统确保了我们在使用m中的值之前
获取锁：Mutex<i32>并不是一个i32，所以必须获取锁才能使用这个i32值。

实质上，Mutex是一个智能指针，lock调用返回一个叫做MutexGuard的智能指针。这个智能
指针实现了Deref来指向其内部数据；同时也提供了一个Drop实现，使得MutexGuard离开作
用域时自动释放锁，即锁的释放是自动发生的。

但是默认情况下，Mutex是无法用于进行线程间的数据共享，如下：
\begin{code-block}{rust}
use std::rc::Rc;
use std::sync::Mutex;
use std::thread;
fn main() {
    let counter = Rc::new(Mutex::new(0));
    let mut handles = vec![];
    for _ in 0..10 {
        let counter = Rc::clone(&counter);
        let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
        });
        handles.push(handle);
    }
    for handle in handles {
        handle.join().unwrap();
    }
    println!("Result: {}", *counter.lock().unwrap());
}
\end{code-block}
上述代码会出现下面的类似错误：
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{rust_mutex_share_error.png}
  \caption{试图通过Rc共享Mutex的数据}
  \label{fig:rust_mutex_share_error}
\end{figure}
即之前提到的，Rc类型只能用于单线程/单进程环境。

而共享引用计数则需要使用Arc，它是可以安全的用于并发环境的类型，即原子引用计数，
可以在线程间进行共享所有权。Arc和Rc有相同的API，基本使用方法上类似。所有，可以直
接对上述代码进行修改：
\begin{code-block}{rust}
use std::sync::{Arc, Mutex};
use std::thread;
fn main() {
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];
    for _ in 0..10 {
        let counter = Arc::clone(&counter);
        let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
        });
        handles.push(handle);
    }
    for handle in handles {
        handle.join().unwrap();
    }
    println!("Result: {}", *counter.lock().unwrap());
}
\end{code-block}
通过这样简单的修改，成功实现了10个进程当中对同一个数值进行加法操作的功能。

虽然Rust本身的线程/进程管理非常完善，但是，thread::spawn产生的线程没有名称，并且
其栈空间大小默认为2M，如果需要需要针对线程/进程进行粒度更细的操作，比如自定义
线程名称，自定义线程的资源等等，此时，就需要使用thread::Builder进行修改，具体示例
如下：
\begin{code-block}{rust}
let mut v_thread = vec![];
for id in 1..5 {
    let thread_name = format!("child-{}", id);
    let size: usize = 1024;
    // 定义线程的名称，设置线程占用的栈大小为1M(1024)
    let builder = Builder::new().name(thread_name).stack_size(size);
    // builder.spawn返回的是Result<JoinHander, std::io::Error>
    // 需要进行处理，取出真正的线程句柄
    match builder.spawn(move || {
        info!(
            "In the child: {}, and the child name is {}",
            id,
            current().name().unwrap()
        );
    }) {
        Ok(child) => v_thread.push(child),
        Err(error) => error!("Cannot create the thread {} because: {:?}", id, error),
    };
}
// 其他的同普通的线程，
for child in v_thread {
    child.join().unwrap();
}
\end{code-block}

由于线程包含自己的资源空间，因此，存在一个特殊的存储空间——线程本地存储（Thread Local Storage，TLS），
存放在该区域的资源，其他线程无法访问，而是每个线程独占的数据：
\begin{code-block}{rust}
use std::cell::RefCell;
use std::thread;
fn main() {
    // 在线程本地存储定义一个FOO变量，最终的类型是thread::LocalKey
    thread_local!(static FOO: RefCell<u32> = RefCell::new(1));
    // 提供了一个with方法，可以通过给该方法传入闭包
    // 来操作线程本地存储中包含的变量
    FOO.with(|f| {
        info!("The f borrow is {}", *f.borrow());
        *f.borrow_mut() = 2;
    });
    let handler = thread::spawn(move || {
        // 子线程也有一个线程本地存储实例FOO，为主线程的副本
        // 也可以使用thread_local!宏在该子线程中重新创建一个LocalKey实例
        FOO.with(|f| {
            info!("In the handler thread The f borrow is {}", *f.borrow());
            *f.borrow_mut() = 3;
        });
    });
    // 主线程当中FOO实例并没有被子线程修改为3
    // thread local!宏定义单个线程内的一些独享数据
    FOO.with(|f| {
        info!("The f borrow is {}", *f.borrow());
    });
    handler.join().unwrap();
}
\end{code-block}

在同步原语支持方面，Rust也有自己的实现方式，通过使用std::thread当中的park函数提供
阻塞线程的能力，但并不能永久的阻塞线程，存在时间限制；而std::thread::part\_timeout
则可以显式的指定阻塞的超时时间；std::thread::Thread::unpark则可以将阻塞的线程重启；
如果需要让出当前线程的时间片，则需要使用std::thread::yeild\_now，让其他线程进行执行。
简单的阻塞例子如下：
\begin{code-block}{rust}
use std::thread::{self, Builder};
use std::time::Duration;
fn main() {
    let parked_thread = Builder::new()
        .spawn(|| {
            info!("Parking the thread ...");
            // 阻塞当前线程
            thread::park();
            info!("Thread parked");
        })
        .unwrap();
    thread::sleep(Duration::from_secs(5));
    info!("Unparking the thread");
    // 从JoinHandle中得到具体的线程
    parked_thread.thread().unpark();
    // 将该线程重新启动，该线程会继续沿着之前暂停的上下文执行
    parked_thread.join().unwrap();
}
\end{code-block}

除了常见的互斥锁（Mutex）之外，Rust也支持读写锁（RwLock）。读写锁的基本示例如下：
\begin{code-block}{rust}
use std::sync::RwLock;
fn main() {
    let rw_lock = RwLock::new(5);
    // 读写锁的使用必须使用{}进行区分，即便是单独使用读或者写也是一样
    // 通过代码块{}，让读写锁自动释放，否则会出现死锁
    {
        let read_1 = rw_lock.read().unwrap();
        let read_2 = rw_lock.read().unwrap();
        info!("The read_1 is {}, and read_2 is {}", read_1, read_2);
    }
    {
        let mut write = rw_lock.write().unwrap();
        *write = 100;
    }
    info!("The data is {:?}", rw_lock);
}
\end{code-block}

而针对于同步的需求，Rust提供了屏障（Barrier）和条件变量（Condition Variable）原语。
屏障，是要求所有的条件全部满足之后，再进行后续操作，即在满足某个条件前，阻塞全部的
线程，通常用于线程同步，如下：
\begin{code-block}{rust}
use std::sync::{Arc, Barrier};
use std::thread;
fn main() {
    let mut vec = vec![];
    let barrier = Arc::new(Barrier::new(5));
    for id in 0..5 {
        let barrier_copy = barrier.clone();
        vec.push(thread::spawn(move || {
            info!("Thread {} Waiting the other threads...", id);
            // wait阻塞了所有的线程，当所有线程的wait之前部分全部执行完成之后
            // wait操作才算执行完成，才会执行每个线程后续的操作
            barrier_copy.wait();
            info!("{} After wait...", id);
        }));
    }
    for handler in vec {
        handler.join().unwrap();
    }
}
\end{code-block}

而条件变量与屏障稍微的区别在于，它不是阻塞所有的线程，而是在满足特定条件前，阻塞
一个得到了互斥锁的线程，如下：
\begin{code-block}{rust}
use std::sync::{Arc, Condvar, Mutex};
use std::thread;
use std::time::Duration;
fn main() {
    // 生成包含互斥锁的条件变量condvar
    let pair = Arc::new(((Mutex::new(false)), Condvar::new()));
    let pair_clone = pair.clone();
    let handler = thread::spawn(move || {
        let &(ref lock, ref cvar) = &*pair_clone;
        // 获得互斥锁
        let mut started = lock.lock().unwrap();
        info!("In the child thread");
        thread::sleep(Duration::from_secs(5));
        *started = true;
        // 通知主线程
        cvar.notify_one();
    });
    let &(ref lock, ref cvar) = &*pair;
    let mut started = lock.lock().unwrap();
    while !*started {
        info!("Waiting for the started singal {} ...", started);
        // 使用条件变量的wait阻塞当前线程，一直到cvar退出
        started = cvar.wait(started).unwrap();
        info!("Started singal finished {} ...", started);
    }
    handler.join().unwrap();
}
\end{code-block}
相比于单纯的互斥锁必须多次出入临界区才能获取到某个状态的信息，条件变量减少了系统
资源的浪费，但是需要注意，每个条件变量每次只能和一个互斥锁（体）一起使用。

除了使用锁、屏障以及条件变量，关于同步的问题，还可以使用原子操作。Rust目前只提供了
4个原子操作类型：AtomicBool、Atomiclsize、AtomicPtr和AtomicUsize。需要注意，虽然原子
操作类型本身可以保证操作的原子性，但是其本身并没有提供跨线程的共享方法，如果需要
使得原子数据类型也可以在线程间共享，则应当使用Arc进行封装，比如下面，使用原子类型
实现一个自旋锁：
\begin{code-block}{rust}
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
fn main() {
    let spinlock = Arc::new(AtomicUsize::new(1));
    let spinlock_clone = spinlock.clone();
    let handler = thread::spawn(move || {
        // 将原子类型的数据设置为0
        spinlock_clone.store(0, Ordering::SeqCst);
    });
    // 使用spinlock的load方法读取其内部原子类型的值，如果不为0，
    // 则不停地循环测试锁的状态，直到其状态被置为0为止
    // 所谓“自旋”就是指在语义上表示这种不断循环获取锁状态的行为
    while spinlock.load(Ordering::SeqCst) != 0 {}
    handler.join().unwrap();
}
\end{code-block}
代码当中的Ordering表示内存参数顺序，可以通过该参数来控制底层线程执行顺序。默认的，
Rust支持5种内存顺序，归为3大类：
\begin{itemize}
  \item 排序一致性顺序——SeqCst：最简单直观，要求必须先存储，后读取，在多线程环境下，所有的原子写操作都必须在读操作之前完成，强行指定了线程的执行顺序，保证了多线程中所有操作的全局一致性，但是存在性能损耗，其实质类似于餐厅点餐，相当于强制要求所有需要结账的客人，必须等所有点单的客户完成之后才可以结账
  \item 自由顺序——Relaxed：和SeqCst相反，完全不会对线程的顺序进行干涉，线程只进行原子操作，但是，线程之间会存在竞态条件，使用这种内存顺序会比较危险，只有在明确了解当前使用场景且必须使用它的情况下（比如只有读操作），才可使用自由顺序
  \item 获取-释放顺序——Release，Acquire和AcqRel： 是除排序一致性顺序之外的优先选择，默认情况下，不会对全部线程进行统一强制性的执行顺序要求，store表示释放（release），而load表示获取（acquire），通过这2种操作的协作实现线程同步。Release表示使用该顺序的store操作，之前所有的操作对于使用Acquire顺序的load操作都可见；反之，使用使用Aquire顺序的load操作，对于使用Release的store操作都是可见的；AcqRel表示读时使用Acquire顺序的load操作，写时使用Release顺序的store操作。获取释放顺序虽然不像排序一致性顺序那样对全局线程统一排序，但是它让每个线程都能接固定的顺序执行。
\end{itemize}

在此之前，已经谈到Rust支持channel通信来解决多线程环境所遇到的问题，比如之前的小例子：
\begin{code-block}{rust}
use std::thread;
use std::sync::mpsc::channel;
fn main() {
    let (tx, rx) = channel();
    let handler = thread::spawn(move || {
        tx.send(10).unwrap();
    });
    let res = rx.recv().unwrap();
    handler.join().unwrap();
}
\end{code-block}
像这种只有2个线程间通信的channel，称之为流通道，在流通道的内部，默认使用的是单生产者
单消费者的模式来提升性能。在此之前，我们看到多个发送者（生产者）单个接收者（消费者）
模式的通道，则称之为共享通道。而由于统一使用的channel函数生成通道，这样的通道又
称之为异步通道，即所有的操作都可以异步的进行处理，不会出现线程阻塞的情况。

同步通道的例子则如下：
\begin{code-block}{rust}
use std::thread;
use std::sync::mpsc::sync_channel;
fn main() {
    // 创建缓冲区为1的同步通道
    let (tx, rx) = sync_channel(1);
    tx.send(1).unwrap();
    let handler = thread::spawn(move || {
        tx.send(2).unwrap();
    });
    let res1 = rx.recv().unwrap();
    info!("The result is {}", res1);
    let res2 = rx.recv().unwrap();
    info!("The result2 is {}", res2);
    handler.join().unwrap();
}
\end{code-block}
在上述代码当中，由于channel的缓冲区设置为1，所以，当第一条信息被消费（recv）之前，
后续的消息发送会被一直阻塞，直到缓冲区可用为止。

虽然channel解决了很多的多线程同步和共享问题，但是，channel并没有解决死锁的问题，
当设计不周到的时候，channel同样会出现死锁的问题：
\begin{code-block}{rust}
use std::thread;
use std::sync::mpsc::channel;
fn main() {
    let (tx, rx) = channel();
    let mut handlers = vec![];
    for i in 0..5 {
        let tc = tx.clone();
        let handler = thread::spawn(move || {
            tc.send(i).unwrap();
        });
        handlers.push(handler);
    }
    // 如果注释下面代码，主线程将一直不退出
    // drop(tx);
    for j in rx.iter() {
        info!("{:?}", j);
    }
    for handler in handlers {
        handler.join().unwrap();
    }
}
\end{code-block}
因为rx的iter方法会阻塞线程，只要tx还没有被析构，该迭代器就会一直等待新的消息，
只有tx被析构之后，迭代器才能返回None，从而结束退出main主线程。由于上述代码的tx
一直没有析构，所以迭代器依旧会进行等待，但是tx也没有发送信息，从而造成死锁的状态。
显式调用drop之后，死锁将不会存在。

\section{异步编程（Future）的基本原理}
Rust目前的版本当中，异步/同步的支持比较完善，通常需要使用Future进行实现，
其中futures\footnote{\url{https://github.com/rust-lang/futures-rs}}提供了一个比较基本的异步编程实现，
Tokio\footnote{\url{https://github.com/tokio-rs/tokio}}也提供了比较完整的平台支持，
Async-Std\footnote{\url{https://github.com/async-rs/async-std}}也提供了
相关的支持。多线程的劣势主要体现在操作系统调度开销，难度较大，线程切换以及
跨线程共享数据会产生很多的额外开销，这些就是异步并发（async/await）发挥作用的
重要场景。

\subsection{Future的基本原理与实现机制}
所谓的Futrue，从字面上讲，就是一些将来完成的操作，也就是一些并不是当前立即结束
的操作，以此指代Rust的异步操作。Rust的异步操作实现基于轮询机制，每个异步任务分成
了3个阶段：
\begin{enumerate}
  \item 轮询阶段（Poll）：一个Future被轮询之后，会开始执行，直到被阻塞。轮询Future通常被称为执行器（executor）
  \item 等待阶段：事件源（即需要使用Future的对象，通常称为reactor）注册等待事件发生，并确保当对应的事件发生或准备好时唤醒对应的Future
  \item 唤醒阶段：事件发生，相应的Future被唤醒，执行器执行，直至完成
\end{enumerate}

例如对大文件进行操作，如果采用普通的文件打开方式，操作大文件，需要将文件内容打开
（全部在内存展开）之后，才能操作；而异步的文件打开，则相当于将文件句柄返回给调用
者，而后续的内容，在调用者需要进行使用时，再加载到内存当中。两者的具体的情况如下
所示：
\begin{figure}[H]
  \centering
  % 禁止svg当中的特殊文字转换
  \includesvg[inkscapelatex=false, width=\linewidth]{rust_async}
  \caption{同步与异步执行的区别\protect\footnotemark}
  \label{fig:rust_async}
\end{figure}
\footnotetext{同/异步：\url{https://os.phil-opp.com/async-await/async-example.svg}}
上述例子当中，轮询阶段就相当于询问文件是否被打开，而等待阶段，则相当于等待文件的
内容加载内存当中，唤醒，则是调用者访问文件内容。

Rust的异步实现依赖于Future。在标准库当中，Rust提供了Future的
Trait以及\codeinlinebg{rust}{async}和\codeinlinebg{rust}{await}2个异步并发的关键字，
但是并没有提供具体的实现（即运行时），运行时则是由其他的库提供的，常见的就包括
上面提到的Async-Std和Tokio，以及Rust官方提供的futures（不在Rust的标准库当中）。
Rust的异步运行时可以分为2部分：执行器（executor）和反应器（reactor），
这2部分则是由Waker（唤醒器）进行交互。

以futures为例，一个简单的异步应用大致如下：
\begin{code-block}{rust}
extern crate futures;
async fn foo() -> u8 { 8 }
async fn hello() {
    let res = foo().await;
    println!("The res is {}", res);
}

fn main() {
    let future = hello();
    futures::executor::block_on(future);
}
\end{code-block}
在上述的例子当中，使用关键字\codeinlinebg{rust}{async}修饰的函数都是异步函数，这些
函数都会返回一个Future Trait，如果不使用\codeinlinebg{rust}{async}关键字，实际上
也是可以实现异步函数的定义的，只不过，会相对比较麻烦，并且需要显式的使用Future，
比如下面的代码：
\begin{code-block}{rust}
use futures::future::{self, Future};
fn async_read_file(name: &str) -> impl Future<Output = String> {
    future::ready(String::from(name))
}
fn async_with_lifetime<'a>(input: &'a u8) -> impl Future<Output = u8> + 'a {
    future::ready(*input)
}
\end{code-block}

Rust的Future Trait的定义如下\footnote{定义：\url{https://doc.rust-lang.org/std/future/trait.Future.html}}：
\begin{code-block}{rust}
pub trait Future {
    type Output;
    fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output>;
}
\end{code-block}
其中，Output指的是异步函数的返回数据类型，而\codeinlinebg{rust}{poll}函数则是整个
Future工作机制的核心。该函数的实质是一个有限状态机，返回的Poll实际上是状态的描述。
Poll的定义如下：
\begin{code-block}{rust}
pub enum Poll<T> {
    Ready(T),
    Pending,
}
\end{code-block}
当异步函数的执行结果完成并且可用时，\codeinlinebg{rust}{poll}函数将返回一个Ready
包裹的结果，表示完成；如果执行还没有结束，则会返回一个Pending，表示执行还将继续，
相关的数据还没有准备完成，需要继续等待或者轮询，并且从当前的context当中，克隆一个
waker，一旦future状态有新的变化，waker函数将被唤醒。注意，如果状态不是Ready，poll函数
会被再次调用（间隔一定时间），直到返回Ready之后，poll函数将不再被调用。如果用普通的
Rust代码进行表示，其内在的逻辑可以模拟如下（但是性能非常差）：
\begin{code-block}{rust}
let future = async_read_file("foo.txt");
let file_content = loop {
    match future.poll(…) {
        Poll::Ready(value) => break value,
        Poll::Pending => {}, // do something
    }
}
\end{code-block}

而另一种思路，则是使用future的组合，比如下方的例子：
\begin{code-block}{rust}
use std::future::{self,Future};
use std::task::{Context, Poll};
use std::pin::Pin;
fn main() {
    let _ = file_len();
}
struct StringLen<F> {
    inner_future: F,
}
impl<F> Future for StringLen<F> where F: Future<Output = String>{
    type Output = usize;
    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        match self.inner_future.poll(cx) {
            Poll::Ready(s) => Poll::Ready(s.len()),
            Poll::Pending => Poll::Pending,
        }
    }
}
fn string_len(string: impl Future<Output = String>)
    -> impl Future<Output = usize>
{
    StringLen {
        inner_future: string,
    }
}
fn file_len() -> impl Future<Output = usize> {
    let file_content_future = async_read_file("foo.txt");
    string_len(file_content_future)
}
fn async_read_file(name: &str) -> impl Future<Output = String> {
    future::ready(String::from(name))
}
\end{code-block}
\begin{attention}
上述代码只是演示了一种Future可能的处理方式，但是，代码本身不可使用，原因在于在
上述代码当中还没有处理pin（固定）。
\end{attention}

通过future的组合，可以实现非常高效的代码，但是，在某些情况下，由于Rust的类型系统
以及基于闭包的接口，会使得future的组合使用起来比较难，比如下面的代码：
\begin{code-block}{rust}
use futures::future::{self, Either, Future, FutureExt};
fn main() {
    let _ = example(100);
}
fn example(min_len: usize) -> impl Future<Output = String> {
    async_read_file("foo.txt").then(move |content| {
        if content.len() < min_len {
            Either::Left(async_read_file("bar.txt").map(|s| content + &s))
        } else {
            Either::Right(future::ready(content))
        }
    })
}
fn async_read_file(name: &str) -> impl Future<Output = String> {
    future::ready(String::from(name))
}
\end{code-block}
上述代码的功能很简单，读取foo.txt文件，然后使用\codeinlinebg{rust}{then}连接第二个
future：如果foo.txt的内容长度小于给定的最小值，则读取另一个文件bar.txt的内容，并将
其长度追加到返回结果当中，否则，只返回foo.txt的内容。上述操作当中，必须使用\codeinlinebg{rust}{move}
关键字，否则会存在一个生命周期的错误；另外，if/else必须返回相同的类型，但是，
上述代码当中，if返回的是\codeinlinebg{rust}{futures::future::Map}，而else返回的是\codeinlinebg{rust}{futures::future::Ready}，
必须使用\codeinlinebg{rust}{Either}将结果进行封装，转换成所期望的future。

\subsection{Future的async/await模式}
从上面的各种例子都可以看到，使用普通的方式实现Rust的异步编程可能会涉及到非常复杂的
代码，于是，Rust官方使用\codeinlinebg{rust}{async/await}等关键字，来简化异步编程的实现，
屏蔽了繁琐的实现细节。使用上述两个关键字之后，Rust的编译器会在编译过程当中进行
自动转换，转换成Future的模式，比如：
\begin{code-block}{rust}
async fn foo() -> u32 {
    0
}
// 编译器内部会自动转换成这种模式
fn foo() -> impl Future<Output = u32> {
    future::ready(0)
}
\end{code-block}

但是，这个转换过程对于开发者而言是透明无感的，以上面代码为例，使用async/await
进行改写之后的结果大致如下：
\begin{code-block}{rust}
async fn example(min_len: usize) -> String {
    let content = async_read_file("foo.txt").await;
    if content.len() < min_len {
        content + &async_read_file("bar.txt").await
    } else {
        content
    }
}
\end{code-block}
可以看到，代码更加的简练，并且逻辑上也是非常清晰。

但是，不管怎么变换，Future的内在还是一个有限状态机。\codeinlinebg{rust}{async}负责
将对应的函数转换成有限状态机，而\codeinlinebg{rust}{await}调用代表了不同的状态。
在上述代码当中，编译器将创建一个具有4个状态的状态机：
\begin{figure}[H]
  \centering
  \includesvg[inkscapelatex=false, width=\linewidth]{async-state-machine-states}
  \caption{异步状态机\protect\footnotemark}
  \label{fig:async-state-machine-states}
\end{figure}
\footnotetext{状态机：\url{https://os.phil-opp.com/async-await/async-state-machine-states.svg}}
\begin{enumerate}
  \item Start/End表示函数执行的开始和结束
  \item \colorblock{Waiting on foo.txt}状态表示该函数当前正在等待第一个async\_read\_file结果，表示一个暂停点
  \item \colorblock{Waiting on bar.txt}状态表示函数等待第二个async\_read\_file结果，同样也是一个暂停点
\end{enumerate}

有限状态机通过调用\codeinlinebg{rust}{poll}函数实现状态的切换，从而实现Future Trait：
\begin{figure}[H]
  \centering
  \begin{minipage}{\textwidth}
  \includesvg[inkscapelatex=false, width=\linewidth]{async-state-machine-basic}
  \caption{状态机切换\protect\footnotemark}
  \label{fig:async-state-machine-basic}
  \end{minipage}
\end{figure}
\footnotetext{状态转换：\url{https://os.phil-opp.com/async-await/async-state-machine-basic.svg}}

为了从最后一个等待状态继续，状态机必须在自身内部保持对当前状态的跟踪。此外，还必须
保存将在下一次poll调用当中需要被使用到的全部变量。幸运的是Rust编译器知道什么时候
使用哪些变量，因此，它可以自动生成包含了所需变量的结构体，注意，是\colorblock{自动生成}。
同样以上面的代码为例，如果深入到Rust编译器内部，看到的代码可能会是下面的样子：
\begin{code-block}{rust}
async fn example(min_len: usize) -> String {
    let content = async_read_file("foo.txt").await;
    if content.len() < min_len {
        content + &async_read_file("bar.txt").await
    } else {
        content
    }
}
// 注意，下面的代码是编译器自动生成的，不是开发者手动编写的
struct StartState {
    min_len: usize,
}
struct WaitingOnFooTxtState {
    min_len: usize,
    foo_txt_future: impl Future<Output = String>,
}
struct WaitingOnBarTxtState {
    content: String,
    bar_txt_future: impl Future<Output = String>,
}
struct EndState {}
\end{code-block}

在\colorblock{start}和\colorblock{Waiting on foo.txt}状态下，需要保存min\_len参数，
是因为在后面需要和content的长度进行比较，\colorblock{Waiting on foo.txt}状态保存
了另外一个foo\_txt\_future，代表了async\_read\_file的调用所返回的future，而这个
future会被状态机继续轮询，因此需要保留；\colorblock{Waiting on bar.txt}状态包含
内容变量，因为在bar.txt准备好后，字符串连接操作需要它。它还存储一个bar\_txt\_future，
表示bar.txt的正在进行的加载。该结构不包含min\_len变量，因为在content.len()比较之
后不再需要它。 在\colorblock{stop}状态下，不存储任何变量，因为该函数已经运行完成。

同样的，编译器也会自动生成状态机相关的代码，以上面的代码为例，Rust编译器会在内部
生成类似如下的状态机代码：
\begin{code-block}{rust}
enum ExampleStateMachine {
    Start(StartState),
    WaitingOnFooTxt(WaitingOnFooTxtState),
    WaitingOnBarTxt(WaitingOnBarTxtState),
    End(EndState),
}
\end{code-block}

使用编译器已经生成的各种状态结构体，利用enum将其进行封装成顶层的状态机，在此基础上，
为了完成/实现状态之前的切换，Rust编译器会根据上面的example函数自动生成其Future Trait
的实现，注意，下列代码也是Rust自动生成的，但并不代表编译器生成的代码就一定是下面
的样子：
\begin{code-block}{rust}
impl Future for ExampleStateMachine {
    type Output = String; // return type of `example`
    fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {
        loop {
            match self { // TODO: handle pinning
                ExampleStateMachine::Start(state) => {…}
                ExampleStateMachine::WaitingOnFooTxt(state) => {…}
                ExampleStateMachine::WaitingOnBarTxt(state) => {…}
                ExampleStateMachine::End(state) => {…}
            }
        }
    }
}
\end{code-block}

状态机的Future实现关联数据类型Output为String，原因是异步函数example的返回类型是
String；同样的，由于Future Trait的定义当中包含了poll函数，因此，编译器又不辞辛劳
的生成或者说是实现了poll函数，在该函数体当中，使用loop-match对当前的状态进行轮询
和切换。当然，为了简单起见，这些编译器生成的代码都没有包含pin（固定，后续会专门
进行讲解），所有权以及生命周期等，因此，这些代码应当被视为不可运行的伪代码，而
编译器生成的真实代码，毫无疑问是可以处理上述的所有特性和问题的。

为了更进一步的理解Future Trait的内部实现机制，接下来会针对match的不同分支进行分析：
\begin{outline}[enumerate]
\1 Start分支

Rust编译器生成的Start分支的代码可能如下：
\begin{code-block}{rust}
ExampleStateMachine::Start(state) => {
    // from body of `example`
    let foo_txt_future = async_read_file("foo.txt");
    // `.await` operation
    let state = WaitingOnFooTxtState {
        min_len: state.min_len,
        foo_txt_future,
    };
    *self = ExampleStateMachine::WaitingOnFooTxt(state);
}
\end{code-block}
在example函数开始的时候，状态机实际上处于Start状态，在这种状态下，会执行example函数
体当中的代码，直到遇到第一个await关键字，即执行\codeinlinebg{rust}{async_read_file("foo.txt")}
这句，而为了处理该函数后面的await操作，编译器需要将状态机的状态修改为WaitingOnFooTxtState。
由于loop-match操作，状态机会跳入到WaitingOnFooTxtState分支。

\1 WaitingOnFooTxtState分支

同样的，该分支的代码（编译器自动生成）的可能如下：
\begin{code-block}{rust}
ExampleStateMachine::WaitingOnFooTxt(state) => {
    match state.foo_txt_future.poll(cx) {
        Poll::Pending => return Poll::Pending,
        Poll::Ready(content) => {
            // from body of `example`
            if content.len() < state.min_len {
                let bar_txt_future = async_read_file("bar.txt");
                // `.await` operation
                let state = WaitingOnBarTxtState { content, bar_txt_future, };
                *self = ExampleStateMachine::WaitingOnBarTxt(state);
            } else {
                *self = ExampleStateMachine::End(EndState));
                return Poll::Ready(content);
            }
        }
    }
}
\end{code-block}
注意，从该分支开始，poll函数被第一次调用，这是因为我们要获得foo\_txt\_future这个
future的真实结果，如果该结果没有准备好，则退出循环，返回pending状态；由于本次
循环当中，状态机实例（self）还是处于WaitingOnFooTxt状态，因此，下一次的轮询调用
仍然会执行当前的分支，不会进行状态切换（即进入其他的分支）。当foo\_txt\_future
准备就绪之后，结果将赋给content变量，如果content的长度满足最小长度，则状态机的
状态将被切换成EndState，直接返回一个Ready，结束轮询；否则，将异步读取bar.txt文件，
并再次通过await关键字将状态进行切换成为WaitingOnBarTxtState，而后续的轮询操作将进入
WaitingOnBarTxt这个分支。该分支的执行情况与本分支的类似。

\1 End分支

End分支应该是最为简单的分支，编译器生成的代码可能如下：
\begin{code-block}{rust}
ExampleStateMachine::End(_) => {
    panic!("poll called after Poll::Ready was returned");
}
\end{code-block}

实际上，一旦状态机变成了End状态，或者返回了Ready状态，就不能也不应该再次进行轮询，
而是直接退出循环和轮询，因此，如果是在End状态再次调用了poll函数，应当直接进行panic
处理。
\end{outline}

通过上述的模拟和分析大致理解编译器生成的状态机以及Future Trait的实现机制可能是
什么样的，实际上，编译器可以使用多种不同的方式实现或者生成Futrure Trait的代码，
目前看到的例子是基于生成器实现的。

目前还缺少异步函数本身的处理，要知道，原始的异步函数定义本身是下面的样式：
\begin{code-block}{rust}
async fn example(min_len: usize) -> String
\end{code-block}
由于完整的函数体是由状态机实现的（编译器内部/编译器视角），因此，编译器目前对原始
的异步函数做的唯一事情就是初始化状态机并返回它。编译器自动生成的相关代码可能如下：
\begin{code-block}{rust}
fn example(min_len: usize) -> ExampleStateMachine {
    ExampleStateMachine::Start(StartState { min_len, })
}
\end{code-block}
这个函数不再包含async关键字，取而代之的，则是返回状态机类型（ExampleStateMachine），
毫无疑问这个类型实现了Future Trait。如同上面的示例显示的一样，状态机在Start状态
当中被构造，并且使用min\_len参数初始化相应的状态结构体，一个Future在Rust编译器当
中是如何实现以及转换的大致过程就如同上述描述的过程。

\subsection{Future的pinning（锚点/固定）}
在之前的介绍当中已经提到了pinning，那pinning到底是什么。不过，先决条件是，需要了解
自引用结构（Self-Referential Structs）。所谓自引用结构，就是一个结构体当中包含了一个
字段，该字段直接引用了当前结构体当中的其他字段，或者该字段直接指向了当前结构体当中
的某个字段。

比如上面的Rust编译器实现的状态机，当其进行状态转换需要将每个暂停点的局部变量存储
在一个结构中，就属于一种简单的自引用结构的实际应用。对于类似于example这样的小函数，
一般不会出现问题，然而，当出现变量相互引用时，情况会变得更加的复杂，比如下面的代码：
\begin{code-block}{rust}
async fn pin_example() -> i32 {
    let array = [1, 2, 3];
    let element = &array[2];
    async_write_file("foo.txt", element.to_string()).await;
    *element
}
\end{code-block}

该函数创建了一个数组，然后创建了一个对数组最后一个元素的引用（地址），将其存储
在一个变量当中，并将该变量转换成字符串异步的写入一个文件当中，最后再返回该变量
所引用的数据。由于该函数只使用了一个await操作，因此，Rust编译器生成的状态机只有
3种：start，end和“wait on write”；由于该函数无参数传入，因此，start状态的结构体
是空的，与end状态的结构体类似，但是，“wait on write”的状态结构体会存在比较大的变化：
\begin{code-block}{rust}
struct WaitingOnWriteState {
    array: [1, 2, 3],
    element: 0x1001c, // array数组最后一个元素的地址
}
\end{code-block}

因为要返回array的元素值，并且返回的元素由element所代表的地址所引用，因此编译器
需要同时存储结构体的array和element。由于element本身代表了一个地址引用，存储的是
一个指向被引用元素的指针（内存地址），在这里使用0x1001c作为示例内存地址。该地址
指向数组array的最后一个元素，因此，它的实际内容取决于结构体在内存当中的位置。像
这种具有这种指向内部的结构体被称为\colorblock{自引用结构}，这种结构体可以使用自身的一个字段
来引用或者指向自己。

一般情况下，自引用结构在使用时和普通的结构并没有太大的区别，但是它在内存排列和管理
上，会带来一些问题，下图是上面的自引用结构体的内存示意图：
\begin{figure}[H]
  \centering
  \includesvg[inkscapelatex=false, width=\linewidth]{self-referential-struct}
  \caption{自引用结构的内存分布示意图\protect\footnotemark}
  \label{fig:self-referential-struct}
\end{figure}
\footnotetext{内存分布：\url{https://os.phil-opp.com/async-await/self-referential-struct.svg}}
如图，结构体当中的array的首地址是0x10014（每个元素4个长度），而element字段的地址
是0x10020，但是element存储的地址是0x1001c（即array最后一个元素的地址）。一切都表现
得很好。不过，一旦结构体在内存当中的地址发生了变化（比如将该结构体当作参数传递，
或者赋值给其他变量），结果就不一样了：
\begin{figure}[H]
  \centering
  \includesvg[inkscapelatex=false, width=\linewidth]{self-referential-struct-moved}
  \caption{移动后的内存分布示意图\protect\footnotemark}
  \label{fig:self-referential-struct-moved}
\end{figure}
\footnotetext{移动后的内存分布：\url{https://os.phil-opp.com/async-await/self-referential-struct-moved.svg}}
字段array的首地址已经变成了0x10024，但是，element字段当中存储的地址还是0x1001c，
这就导致使用element字段引用array的元素时，指向的地址是一个未经初始化的地址，即
指针悬空（相当于C/C++当中常见的野指针），这会直接导致在状态机的下一次轮询的时候
发生未定义的行为。

很显然，这种行为在Rust当中是不安全的，也是编译器严格禁止的，因此需要解决这种不
安全的行为。从现有的理论和实践当中，主要的做法有3种：
\begin{itemize}
  \item 移动时更新内部的指针

  其思想是在结构体在内存中移动时更新内部指针，以便在移动后它仍然有效，比较类似于
  C/C++当中对链表的删除/插入操作。但是，这种做法需要对Rust进行大量的修改，并且会
  造成较大的性能损失，其原因就在于需要跟踪所有结构字段的类型，并检查每个移动操作
  是否需要进行指针更新。

  \item 存储偏移地址而非绝对地址

  即不进行内部指针的更新，内部指针存储的不再是绝对的地址，而是从结构体首地址开始的
  偏移量。由于整体移动结构时，结构内部的地址排列和偏移并不会发生改变，因此，无需
  进行内部指针的更新。但是，这种实现方式要求编译器检查所有的自引用，因为引用的值
  可能来自于用户的输入，因此，这种检查方式几乎是不可能的。

  \item 禁止结构体移动

  如同上面所说，只有在内存当中发生了自引用结构体的移动才会出现悬空指针，当完全
  禁用了自引用结构上的移动操作，自然就避免了悬空指针的出现。这种方式可以在类型
  系统上直接实现。
\end{itemize}

由于第三种方式提供了零成本的抽象，没有增加额外的运行成本，因此被Rust采用，这就是
所谓的\colorblock{Pining（固定/锚点）}。

禁止内存地址移动，或者说固定内存地址，通常可以采取的一种方式是将其放在内存的堆区（heap），
因为堆区分配的值在大多数情况下已经有一个固定的内存地址，在调用allocate时被创建，
直到调用deacllocate将其释放，在此之间，指针指向的堆值将保持在相同的内存地址，
因此可以利用该特性在堆区上创建自引用数据结构：
\begin{code-block}{rust}
fn main() {
    let mut heap_value = Box::new(SelfReferential {
        // 使用0x00当作初始的地址
        self_ptr: 0 as *const _,
    });

    // *heap_value表示从Box指针当中取出真正的元素
    // &*heap_value表示对Box当中的真正元素进行引用（取地址）操作
    // as *const 表示将其转换成对应类型的指针
    let ptr = &*heap_value as *const SelfReferential;

    // 将自身的地址赋给自己的字段
    heap_value.self_ptr = ptr;
    println!("heap value at: {:p}", heap_value);
    println!("internal reference: {:p}", heap_value.self_ptr);
}
struct SelfReferential {
    self_ptr: *const Self,
}
\end{code-block}

结构体SelfReferential包含了一个字段self\_ptr，该字段指向实例本身的地址，构成了
一个自己对自己的引用，如果执行上述代码，可以发现，结构体实例（self）和结构体字段
（self\_ptr）的地址实际上是一样的：
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{self_ref_on_heap.png}
  \caption{堆区实现自引用结构}
  \label{fig:self_ref_on_heap}
\end{figure}

这是一个有效的自引用结构，并且，由于heap\_value只是一个指针，对它的移动操作（
比如赋值给其他变量，或者作为参数传递）并不会改变结构本身的地址，所以，self\_ptr
会一直保持有效。但是，这种“固定效果”很容易被打破或者破坏，比如将Box包裹的数据解引用
或者直接替换：
\begin{code-block}{rust}
use std::mem;

fn main() {
    let mut heap_value = Box::new(SelfReferential {
        self_ptr: 0 as *const _,
    });
    let ptr = &*heap_value as *const SelfReferential;
    heap_value.self_ptr = ptr;
    println!("heap value at: {:p}", heap_value);
    println!("internal reference: {:p}", heap_value.self_ptr);

    // break it
    let stack_value = mem::replace(&mut *heap_value, SelfReferential {
        self_ptr: 0 as *const _,
    });

    println!("value at: {:p}", &stack_value);
    println!("internal reference: {:p}", stack_value.self_ptr);
    let hp = *heap_value;
    println!("heap value at: {:p}", &hp);
    println!("internal reference: {:p}", &(hp.self_ptr));
}
struct SelfReferential { self_ptr: *const Self, }
\end{code-block}
则可以观察到，对应的结构体的内存地址全部发生了变化：
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{self_ref_on_heap_break.png}
  \caption{自引用结构的内存破坏}
  \label{fig:self_ref_on_heap_break}
\end{figure}

\begin{warn}
这种操作是比较危险的，利用mem::replace函数，将原本由堆分配的值替换成新的结构体实例，
即将原始的heap\_value移动到了栈区，此时，self\_ptr变成了悬空指针，仍然指向了原始的
堆区地址，因此，使用堆区分配的方式，并不足以保障自引用结构的安全。
\end{warn}

造成上述问题的根本原因在于Box<T>允许开发者获得一个针对在堆上分配的T的\&mut T的引用，
这使得利用诸如mem::replace/mem::swap这样的函数通过\&mut T实现对堆区数据进行修改
成为可能，从而使得在堆区分配的值失效。为此，针对自引用结构，禁止创建\&mut T这样
的引用是必须的。

Rust的Pinging API通过使用Pin Wrapper类型以及Unpin这个标记型Trait来提供了一种可靠
的解决方案。这种解决方案背后的思路是，搜集所有Pin或者需要进行固定的结构体/类型的
特定方法——这些特定的方法可以通过获取可变的引用（\&mut）来获取被Pin Wrapper包括的
实际类型的值——并将这些方法在Unpin Trait上进行实现；Unpin Trait是一个自动的Trait，
除了那些需要进行显式的选择退出类型，其他所有的类型都实现了它；通过标记自引用结构是
实现的显式选择退出Unpin，这将导致没有任何一个安全（safe）的方法可以从Pin<Box<T>>
类型当中获取一个合法有效的可变引用（\&mut T），因此，这种方式实现的自引用结构，
其内部可以保证内部的自引用一直有效。

利用这种思路，我们可以将之前编写的自引用结构进行改写：
\begin{code-block}{rust}
use core::marker::PhantomPinned;
struct SelfReferential {
    self_ptr: *const Self,
    _pin: PhantomPinned,
}
\end{code-block}

通过在结构体当中插入一个类型为PhantomPinned的字段，我们实现了结构体的选择退出。
PhantomPinned类型是一个零字节大小（不占据内存空间）的标记类型，其作用在于标记对应
的数据类型不实现Unpin Trait。由于Auto Trait的工作机制，该类型（PhantomPinned，
即没有实现Unpin）的标记字段足以影响整个结构体，使之不受Unpin Trait的影响。另外
需要改动的地方，则是将上述的Box<SelfReferential>修改为Pin<Box<SelfReferential>>
类型，实现这个改动，最简单的方式就是用Box::pin，如下：
\begin{code-block}{rust}
let mut heap_value = Box::pin(SelfReferential {
    self_ptr: 0 as *const _,
    _pin: PhantomPinned,
});
\end{code-block}
由于PhantomPinned是零字节大小的类型，因此只需要使用类型名初始化对应的字段即可。
再来看看修正之后的完整代码：
\begin{code-block}{rust}
use std::mem;
use std::marker::PhantomPinned;

fn main() {
    let mut heap_value = Box::pin(SelfReferential {
        self_ptr: 0 as *const _,
        _pin: PhantomPinned,
    });
    let ptr = &*heap_value as *const SelfReferential;
    heap_value.self_ptr = ptr;
    println!("heap value at: {:p}", heap_value);
    println!("internal reference: {:p}", heap_value.self_ptr);
    // break it
    let stack_value = mem::replace(&mut *heap_value, SelfReferential {
        self_ptr: 0 as *const _,
        _pin: PhantomPinned,
    });
    println!("value at: {:p}", &stack_value);
    println!("internal reference: {:p}", stack_value.self_ptr);
}
struct SelfReferential {
    self_ptr: *const Self,
    _pin: PhantomPinned,
}
\end{code-block}
如果对上述代码进行编译，编译器将提示下列的错误：
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{self_ref_pinned.png}
  \caption{Pinned的自引用结构}
  \label{fig:self_ref_pinned}
\end{figure}

这些错误实际上都是由于Pin<Box<SelfReferential>>这种数据类型包含了PhantomPinned这种
特殊的标记数据类型，从而使得整个类型不再实现DerefMut这个Trait，进而导致了错误的发生。
但这实际上正是我们想要的结果：因为DerefMut Trait本身就会返回一个\&mut T的可变引用，
现实的需求要求这种情况的发生。

但是，这也带来了一个额外的负面作用：无法对结构体当中的self\_ptr进行有效的初始化。
这是因为编译器无法区分\&mut引用的有效和无效使用。为了让初始化操作正常进行，使用不安
全的get\_unchecked\_mut方法便成了不多的选择之一：
\begin{code-block}{rust}
unsafe {
    let mut_ref = Pin::as_mut(&mut heap_value);
    // mut_ref.get_unchecked_mut().self_ptr = ptr; 效果和下面相同
    Pin::get_unchecked_mut(mut_ref).self_ptr = ptr;
}
\end{code-block}

get\_unchecked\_mut函数是Pin<\&mut T>而不是Pin<Box<T>>上的函数，因此需要进行一次
转换（as\_mut），并且该函数返回一个\&mut T，因此，可以利用其返回结果进行修改。
到目前为止，还剩下的错误则是replace操作，但该操作试图将在堆区上分配的值移动到栈区，
这会直接破坏存储在self\_ptr当中的自引用。使用Pin以及退出Unpin则可以防止这个移动操作，
从而安全的使用自引用结构。不过，也应当看到，在目前的Rust版本当中，由于编译器还不能
证明或者解决自引用的创建/初始化是安全的，因此，还需要上述的unsafe操作块。

虽然上述的方式可以很好的解决我们所面临的问题，不过由于所有的操作都是在堆上进行，
而堆区内存的分配显而易见的带来了性能损耗。所幸，Rust的Pinning API也允许创建Pin<\&mut T>
这种在内存栈上分配的实例。和Pin<Box<T>>拥有T类型的所有权不同，Pin<\&mut T>只是
针对T的一个临时引用，这使得在内存栈上的Pin变得更加复杂。更重要的是，一个Pin<\&mut T>
必须保证被引用的T在整个生命周期当中都保持固定，但是，这对于基于栈内存的变量是难以
验证的，因此，通常情况下，\colorblock{并不推荐在栈内存上使用Pinning API进行变量固定}。

有了以上的了解之后，利用Pin对之前的示例进行改写：
\begin{code-block}{rust}
use std::mem;
use std::marker::PhantomPinned;
use std::pin::Pin;
use std::future::{self,Future};
use std::task::{Context, Poll};
struct StringLen<F> {
    inner_future: F,
    _pin: PhantomPinned,
}
impl<F> Future for StringLen<F> where F: Future<Output = String> {
    type Output = usize;
    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        match self.as_mut().poll(cx) {
            Poll::Ready(s) => Poll::Ready(s),
            Poll::Pending => Poll::Pending,
        }
    }
}
fn string_len(string: impl Future<Output = String>)
    -> impl Future<Output = usize>
{
    StringLen {
        inner_future: string,
        _pin: PhantomPinned,
    }
}
fn file_len() -> impl Future<Output = usize> {
    let file_content_future = async_read_file("foo.txt");
    string_len(file_content_future)
}
fn async_read_file(name: &str) -> impl Future<Output = String> {
    future::ready(String::from(name))
}
\end{code-block}
虽然这只是一个对Future的简单模拟，但总算是可以编译通过了。正如在上面看到的一样，
async/await创建的实例通常是自引用结构，通过将实例（self）封装在Pin当中，使之退出
Unpin，可以确保对应的Future在轮询调用当中不会在内存当中发生移动，从而确保了所有
的内部引用仍然有效。

不过需要注意的是，在第一次调用轮询poll之前对future进行移动是可以的。这是因为Future
属于懒加载的一种模式，在第一次调用轮询前什么也不会做。因此，编译器生成的状态机
通常情况下只包含了函数参数，但是不包括内部引用。为了轮询调用poll，首先需要将Future
封装到Pin当中，来保证其在内存当中不会发生移动。另外，由于栈区的pinning更加难以操作，
通常情况下，使用Box::Pin配合Pin::as\_mut是一个最优选择。

\subsection{执行器（Executors）与唤醒器（Wakers）}
使用async/await，可以以完全异步的方式处理Future。不过，正如上面所介绍的，Future
在被轮询之前什么也不做。这意味着我们必须在某些时候对它们调用轮询（即唤醒），否则
异步代码永远也不会执行。

对于单个Future，我们总是可以使用上面描述的循环手动等待每个future。然而，这种方法
效率非常低，并且对于包含了大量Future的程序来说也不实用。这个问题最常见的解决方案
是定义一个全局执行器，该执行器负责轮询系统中的所有后续操作，直到它们完成为止。

执行器的目的在于允许Future成为一个独立的任务，然后对这些Future进行轮询，直到这些
Future（任务）全部完成为止。因此，全局的执行器最大的优点在于：当Future返回Poll::Pending
时，执行器可以在不同的Future之间进行切换。由于异步操作总是以并行/并发的方式执行的，
因此CPU通常一直处于忙碌状态，提高了资源的利用率。

由于Rust的标准库并没有提供Future的标准执行器，因此，执行器绝大部分是第三方的类库
进行实现的。这些类库在实现执行器时，通常利用了现代的多核技术，一般是创建一个线程
池来充分利用所有的CPU核。为了避免一次次轮询Future带来的开销，执行器通常和Future
支持的唤醒器（Waker）一起工作。

唤醒器的思路是，一个特殊的waker类型当作参数封装在Context类型当中传递给poll调用，
并且这个类型由执行器创建，异步任务可以使用这个waker表示任务结束。因此执行器可以
不再针对Poll::Pending的Future调用poll操作，而是等待相应的waker通知，比如之前的
简单例子：
\begin{code-block}{rust}
async fn write_file() {
    async_write_file("foo.txt", "Hello").await;
}
\end{code-block}
函数async\_write\_file异步地将字符串“Hello”写入foo.txt文件，由于硬盘写入需要一些
时间，因此针对Future的第一个poll调用可能会返回poll::Pending。不过，硬盘驱动程序
可以在内部存储传递给poll调用的Waker，并在文件被写入磁盘时使用它通知执行程序（执行者，Executor）。
通过这种方式，执行器在收到唤醒器通知之前就不需要浪费任何时间再次对Future进行poll调用。

虽然Rust并没有自己提供的标准执行器和唤醒器，但是可以利用Rust提供的标准库，自己
实现一个简单的执行器和唤醒器！在实现自己的执行器和唤醒器之前，我们需要了解一下多任务。
在操作系统当中，并行/并发都涉及到了多任务处理。而多任务处理主要有2种方式：抢占式
多任务以及协作式多任务。抢占式多任务依赖于操作系统在运行的任务之间强制切换，而
协作式多任务则要求任务通过yield或者同类型的操作定期自动放弃对CPU的控制。协作方法
的最大优点是任务可以自己保存状态，从而实现更有效的上下文切换，并使任务之间共享
相同的调用堆栈成为可能。而Rust的Future和async/await是合作多任务模式，因此，在实
现自己的执行器和唤醒器时，需要注意下列的需求：
\begin{itemize}
  \item 每一个添加到执行器当中future都是协作式任务（task，有些时候会将future直接当作task看待）
  \item Future不是通过yield操作，而是通过返回Poll::Pending或Poll::Ready来放弃对CPU的控制权
  \begin{itemize}
    \item 没有任何操作可以强制future放弃CPU的控制权，除非future永远不从poll操作返回，比如在无限循环当中自旋（spinning lock）
    \item 每一个future都可以或者可能阻塞执行器当中的其他future的执行过程，需要保证每个future都不是“恶意的”
  \end{itemize}
  \item Future会在内部存储所有在下一次poll调用时会被使用到的状态/状态。通过async/await，编译器会自动检测所需要的所有变量，并将其存储在生成的状态机当中
  \begin{itemize}
    \item 通常只保存所需要的最少变量
    \item 由于poll操作返回时会放弃对应的堆栈区，因此可以使用相同的堆栈区去轮询其他的future
  \end{itemize}
\end{itemize}

在接下来的示例当中将使用标准库（std）来实现一个Future的完成运行流程，包括执行器和
唤醒器的实现。首先编写我们的异步函数：
\begin{code-block}{rust}
async fn async_number() -> u32 {
    42
}
async fn example_task() {
    let number = async_number().await;
    println!("async number: {}", number);
}
\end{code-block}

async\_number是一个异步函数，Rust编译器会将其在内部转换成状态机。由于该函数只是
返回一个数字，所以在第一次轮询操作（poll）结束时该函数最终会直接返回一个Poll::Ready(42)。
example\_task类似，只是该函数需要等待async\_number的返回结果。Future已经通过async/await
生成好了（example\_task返回的），如果想要运行这个future，则需要对它调用poll操作，
直到接收到Poll::Ready所代表的完成信号为止。因此，现在需要一个任务管理器：
\begin{code-block}{rust}
use std::future::Future;
use std::pin::Pin;
pub struct Task {
    future: Pin<Box<dyn Future<Output = ()>>>,
}
\end{code-block}
该任务（task）结构体是一个包裹类型，包裹了一个具有Pinned属性的、在堆上动态分配的动态Future
类型，并且，这个Future类型的输出类型（即关联类型Output）为空类型。该结构体有如下特点：
\begin{itemize}
  \item Future的关联类型返回()，表示任务（即future）不会返回任何结果，我们的目的仅仅只是使得这个future可以正常运行
  \item dyn关键字表示存储在Box当中的是一个Trait对象，意味着future的方法是动态分配的，这使得在Task类型当中存储不同类型的Future成为可能，也使得可以创建多个不同的任务（future）
  \item Pin保证包裹的对象不能在内存当中移动，防止状态机产生的自引用结构失效
\end{itemize}

接下来实现Task结构体的初始化（new）方法以及poll方法，由于需要使用Task结构体轮询
存储在内存当中的future，因此，poll方法是必需的：
\begin{code-block}{rust}
impl Task {
    pub fn new(future: impl Future<Output = ()> + 'static) -> Task {
        Task {
            future: Box::pin(future),
        }
    }
    fn poll(&mut self, context: &mut Context) -> Poll<()> {
        self.future.as_mut().poll(context)
    }
}
\end{code-block}
new方法接收一个关联类型为()的任意Future，并且通过Box::pin将其在内存当中固定，然后
封装在Task结构体当中进行返回。需要注意，这里需要一个static的生命周期，因为返回的
Task可以在任意时间存在，所以，Future也需要在任意时间内有效。

由于Future Trait的poll方法定义为\codeinline{rust}{fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output>;}，
因此，首先需要通过as\_mut方法将self.future从\codeinlinebg{rust}{Pin<Box<T>>}（Box::pin的返回）转换成
Pin<\&mut T>，然后对转换之后的future调用poll函数。由于Task::poll方法应该只由稍后
创建的执行器调用，因此需要将该函数设置为私有模式。

接下来构造一个简单的执行器：
\begin{code-block}{rust}
pub struct SimpleExecutor {
    task_queue: VecDeque<Task>,
}

impl SimpleExecutor {
    pub fn new() -> SimpleExecutor {
        SimpleExecutor {
            task_queue: VecDeque::new(),
        }
    }
    pub fn spawn(&mut self, task: Task) {
        self.task_queue.push_back(task)
    }
}
\end{code-block}
该执行器包含了一个双端队列，通过spawn方法在队列尾部插入新的任务，从队列头部弹出下一个
任务进行执行。

为了调用Future的poll方法，接下来需要创建一个Context类型的对象，这个对象封装了一个
唤醒器（Waker）来监听Future的完成状态。为此，首先创建一个RawWaker实例，它定义了
不同Waker方法的实现，然后使用Waker::from\_raw函数将其转换为Waker。
\begin{code-block}{rust}
fn dummy_waker() -> Waker {
    unsafe { Waker::from_raw(dummy_raw_waker()) }
}

fn dummy_raw_waker() -> RawWaker {
    fn no_op(_: *const ()) {}
    fn clone(_: *const ()) -> RawWaker {
        dummy_raw_waker()
    }
    let vtable = &RawWakerVTable::new(clone, no_op, no_op, no_op);
    RawWaker::new(0 as *const (), vtable)
}
\end{code-block}

RawWaker类型需要显式地定义一个函数虚表（vtable），这个虚表当中需要包含RawWaker被
复制（clone），唤醒（woken）以及销毁（dropped）时应该被调用的函数。这几个函数的
形式应当如下：
\begin{code-block}{rust}
clone: unsafe fn(*const ()) -> RawWaker,
wake: unsafe fn(*const ()),
wake_by_ref: unsafe fn(*const ()),
drop: unsafe fn(*const ()),
\end{code-block}
这个虚表的布局是由RawWakerVTable类型定义的，每个函数都接收一个*const()参数，它
基本上是一个类型擦除（不关心）的\&self指针，指向某个结构体，例如分配在堆上。使用*const()
指针而不是正确的引用的原因是RawWaker类型应该是非泛型的，但仍然应该支持任意类型。

一般情况下，RawWaker是为包装在Box或Arc类型中的某些在堆区分配的结构所创建的。
对于这类类型，可以使用Box::into\_raw之类的方法将Box<T>转换成*const T指针，而这种
类型的指针可以被转换为一个匿名*const()指针，并传递给RawWaker::new方法。由于每个
虚表函数都接收相同的*const()作为实参，因此函数可以安全地将指针强制转换回Box<T>
或者是一个\&T来操作它。但是这样的操作会涉及到指针的强制转换，因此整个
过程实际上是非常危险的，非常容易导致错误的行为。\colorblock{除非必要，不建议手动
创建RawWaker}。

在上述的代码当中，首先定义了2个内部函数no\_op和clone。这2个函数都接收一个*const()指针
作为参数，不同的是，no\_op不做任何处理和操作，而clone函数通过调用dummy\_raw\_waker
返回一个新的RawWaker。接下来使用这两个函数来创建一个最小的RawWakerVTable：clone函数
用于clone操作，no\_op函数用于所有其他操作。

虚表创建成功之后，再使用RawWaker::new函数来创建RawWaker。由于虚表函数并没有使用第一个
参数，因此，在创建RawWaker时，第一个参数使用了空指针作为代替（0 as *const()）。

有了唤醒器，我们就可以在执行器上实现一个run方法来调用这个唤醒器。最简单的运行方法
就是在循环中反复轮询所有排队的任务，直到全部完成。注意，这并不是很有效，因为它没
有利用Waker类型的通知机制，不过这并不影响它的正常运行，如下代码所示：
\begin{code-block}{rust}
impl SimpleExecutor {
    pub fn run(&mut self) {
        while let Some(mut task) = self.task_queue.pop_front() {
            let waker = dummy_waker();
            let mut context = Context::from_waker(&waker);
            match task.poll(&mut context) {
                Poll::Ready(()) => {} // task done
                Poll::Pending => self.task_queue.push_back(task),
            }
        }
    }
}
\end{code-block}
该函数使用while-loop来处理task\_queue中的所有任务。对于每个任务，它首先通过
由dummy\_waker函数返回的Waker实例来创建一个Context类型的实例，然后对每个任务
调用poll进行轮询，如果poll方法返回poll::Ready，则任务结束，接着下一个任务；
如果任务仍然是Poll::Pending，我们将它再次添加到队列的后面，以便在后续循环迭代中
再次轮询它，直到该任务执行完毕。

接下来看一下完整的代码：
\begin{code-block}{rust}
use std::collections::VecDeque;
use std::future::Future;
use std::pin::Pin;
use std::task::{Context, Poll,Waker, RawWaker,RawWakerVTable};
pub struct Task {
    future: Pin<Box<dyn Future<Output = ()>>>,
}
impl Task {
    pub fn new(future: impl Future<Output = ()> + 'static) -> Task {
        Task { future: Box::pin(future), }
    }
    fn poll(&mut self, context: &mut Context) -> Poll<()> {
        self.future.as_mut().poll(context)
    }
}
pub struct SimpleExecutor { task_queue: VecDeque<Task>, }
impl SimpleExecutor {
    pub fn new() -> SimpleExecutor {
        SimpleExecutor { task_queue: VecDeque::new(), }
    }
    pub fn spawn(&mut self, task: Task) {
        self.task_queue.push_back(task)
    }
    pub fn run(&mut self) {
        while let Some(mut task) = self.task_queue.pop_front() {
            let waker = dummy_waker();
            let mut context = Context::from_waker(&waker);
            match task.poll(&mut context) {
                Poll::Ready(()) => {} // task done
                Poll::Pending => self.task_queue.push_back(task),
            }
        }
    }
}
fn dummy_waker() -> Waker {
    unsafe { Waker::from_raw(dummy_raw_waker()) }
}
fn dummy_raw_waker() -> RawWaker {
    fn no_op(_: *const ()) {}
    fn clone(_: *const ()) -> RawWaker { dummy_raw_waker() }
    let vtable = &RawWakerVTable::new(clone, no_op, no_op, no_op);
    RawWaker::new(0 as *const (), vtable)
}
async fn async_number() -> u32 { 42 }
async fn example_task() {
    let number = async_number().await;
    println!("async number: {}", number);
}
fn main() {
    let mut executor = SimpleExecutor::new();
    executor.spawn(Task::new(example_task()));
    executor.run();
}
\end{code-block}

到此为止，Future的整体运行机制以及执行器的实现思路已经明白无误的剖析在了面前，
并且上述代码全部使用Rust的标准库（std）实现的。从上面的例子可以看到，Rust的标准
库针对Future只保证下列的必需条件：
\begin{itemize}
  \item 标准的Future Trait
  \item 一个合乎常理的方法创建任务，并且可以通过async/await对Future进行暂停/恢复
  \item 标准的Waker Trait，可以唤醒暂停的Future
\end{itemize}
但是，\colorblock{并不包含异步任务的执行}。

\begin{note}
Future，Waker以及相关的Task，在标准库（std）当中存在，在核心库（core）当中也存在，
并且，std和core当中的定义和实现是一模一样的，因此，async/await以及Future等异步
操作不仅可以用于普通的Rust开发，也同样可以用于没有std模式的嵌入式开发，甚至是操作
系统开发。除此之外，其他常用的异步开发框架，比如futures，async-std等，其内部定义
的Future，Waker以及Task等Trait，和Rust std都是完全相同的。这些类库当中的相关Trait
完全等价，使用时无需进行转换。不过，确切的说，除了core当中的Future定义，
Future的定义只有2类：一种是std当中的，而另外一种则是future-rs提供的futures::future::Future，
其中future-rs当中的是最原始的定义，而为了给Rust提供异步支持，才将future-rs当中的
相关定义移入到了std当中，也就是说，std当中的Future实际上是future-rs的最小子集。
而同样的，async-std、tokio等类库当中的Future实现，实际上也是future-rs的重新导出。
\end{note}
\subsection{Future补遗}
\subsubsection{胖指针与虚表}
Rust当中也存在指针，但是存在一些特殊的指针，比如下面的代码：
\begin{code-block}{rust}
use std::mem::size_of;
trait SomeTrait {}
fn main() {
    info!("======== The size of different pointers in Rust: ========");
    info!("&dyn Trait:-----{}", size_of::<&dyn SomeTrait>());
    info!("&[&dyn Trait]:--{}", size_of::<&[&dyn SomeTrait]>());
    info!("Box<Trait>:-----{}", size_of::<Box<dyn SomeTrait>>());
    info!("&i32:-----------{}", size_of::<&i32>());
    info!("&[i32]:---------{}", size_of::<&[i32]>());
    info!("Box<i32>:-------{}", size_of::<Box<i32>>());
    info!("&Box<i32>:------{}", size_of::<&Box<i32>>());
    info!("[&dyn Trait;4]:-{}", size_of::<[&dyn SomeTrait; 4]>());
    info!("[i32;4]:--------{}", size_of::<[i32; 4]>());
}
\end{code-block}
如果执行上述代码，我们会发现每个指针的大小都不一样:
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{fat_pointer.png}
  \caption{不同类型的指针}
  \label{fig:fat_pointer}
\end{figure}
有的是8字节大小（64位系统的默认指针大小），而有的则是16字节。这些16字节的指针，就是
所谓的胖指针（Fat Pointer）。胖指针通常携带了额外的信息：
\begin{itemize}
  \item \&[i32]以及[i32;4]
  \begin{itemize}
    \item 前8个字节是指向数组中第一个元素的实际指针，或 slice 引用的数组的一部分
    \item 后8个字节，则表示的是切片以及数组的长度
  \end{itemize}
  \item \&dyn Trait
  \begin{itemize}
    \item 前8个字节指向Trait对象的数据段（data）
    \item 后8个字节指向Trait对象的虚表（vtable）
  \end{itemize}
\end{itemize}
正是由于虚表和胖指针的存在，才使得Rust的Trait如同Java的Interface、C++的虚函数、
C的函数指针一样，可以针对不同的类型进行操作。我们可以直接使用代码来模拟Trait是如何
使用胖指针和虚表来实现动态分发（针对不同的类型使用相同的方法定义）的：
\begin{code-block}{rust}
use std::mem::transmute;
trait SomeTrait {
    fn add(&self) -> i32;
    fn sub(&self) -> i32;
    fn mul(&self) -> i32;
}
// 结构体的内存布局和对齐方式采用兼容C语言的模式进行
#[repr(C)]
struct FatPointer<'a> {
    // 使用data指向Trait的数据段
    data: &'a mut Data,
    // 指向Trait的vtable段。由于需要传入长度和对齐等字面值，
    // 因此最容易的方法是使用无符号数的指针
    vtable: *const usize,
}
struct Data {
    a: i32,
    b: i32,
}
fn add(s: &Data) -> i32 {
    s.a + s.b
}
fn sub(s: &Data) -> i32 {
    s.a - s.b
}
fn mul(s: &Data) -> i32 {
    s.a * s.b
}
fn main() {
    let mut data = Data { a: 3, b: 4 };
    // 使用vec构造一个类似的虚表结构
    // 虚表（vtable）是具有固定格式的特殊用途的指针数组，
    // 每个元素都有特殊的含义
    let vtable = vec![
        0,  // 指向Drop的指针，这里的0表示NULL/None，即在这个虚表当中没有实现drop函数
        6,  // 虚表的长度
        8,  // 虚表当中元素的对其方式，此处表示按照8字节对齐

        // 从第4个元素开始，表示的是Trait当中定义的字段/方法
        // 这里的字段顺序必须和Trait当中定义的顺序相同
        add as usize, // 函数指针
        sub as usize,
        mul as usize
    ];
    let fat_pointer = FatPointer {
        data: &mut data,
        // 将vtable转换成指针
        vtable: vtable.as_ptr(),
    };
    // 使用transmute将fat_pointer转换成 dyn SomeTrait的对象
    // 等同于 let res: &dyn SomeTrait = unsafe { transmute(fat_pointer) };
    let res = unsafe { transmute::<FatPointer, &dyn SomeTrait>(fat_pointer) };
    info!("{}", res.add());
    info!("{}", res.sub());
    info!("{}", res.mul());
}
\end{code-block}

实际上，上述代码的模拟与Rust标准库的Trait非常类似，可以参考TraitOjbect的定义
\footnote{TraitObject：\url{https://doc.rust-lang.org/std/raw/struct.TraitObject.html}}。
虽然Rust的源代码实现有些区别，但Trait的实现方式，其工作机制和模式，可以通过上述
的代码全部展现出来。

\subsubsection{Future的基本使用方式}
虽然对Future的原理和实现方式有了大致的了解，但是Future的使用方式，还没有进行介绍。
Future基本分为2大类：async/await修饰的普通函数，以及实现Future Trait的结构体。这
2种的类型的使用方式类似，唯一有区别的是，结构体需要实现Future Trait的相关方法，
如下的代码所示：
\begin{code-block}{rust}
use std::task::{Context,Poll};
use std::pin::Pin;
use futures::future::Future;
use futures::executor::block_on;

pub struct Number {
    number: u8,
    polled: bool,
}

impl Number {
    pub fn new(number: u8) -> Self {
       Self {
            number: number,
            polled: false,
       }
    }
}

// 结构体实现Future Trait
impl Future for Number {
    type Output = u8;
    fn poll(
       self: Pin<&mut Self>,
       cx: &mut Context<'_>,
    ) -> Poll<Self::Output> {
        let mut this = self.get_mut();
        if this.polled {
            Poll::Ready(this.number)
        } else {
            // 调用唤醒器，否则调用poll时会直接进入死循环
            cx.waker().wake_by_ref();
            this.polled = true;
            Poll::Pending
        }
    }
}

async fn get_num() -> u8 {
    18
}

async fn outer() -> u8 {
    get_num().await
}

fn main(){
    let num = Number::new(98);
    // 将num对象当作一个future使用
    let res = block_on(num);
    println!("{}", res);
    // 同上
    let num = async { Number::new(100).await };
    let res = block_on(num);
    println!("{}", res);
    // 将异步函数当作future使用，2种不同的使用方式
    //let num = async {get_num().await};
    let num = get_num();
    let res = block_on(num);
    println!("{}", res);
    // 将异步函数当作future使用，2种不同的使用方式
    //let res = async {outer().await};
    let res = outer();
    let res = block_on(res);
    println!("{}", res);
}
\end{code-block}

\section{异步编程的实现方案-async-std}
Async-std是一种Future执行器的实现方案。其基本的使用于futures类似，都是使用block\_on
设置异步任务的阻塞运行。相比于futures，async-std提供了一些扩展功能，比如异步的
计时器等。

常见的使用方式都是相同的：
\begin{code-block}{rust}
use async_std::task::block_on;
pub async fn async_hello() {
    info!("This is the async hello");
}

fn main() {
    let _ = block_on(async_hello());
}

\end{code-block}

不过，async-std也还提供了一种简便的方式，这种方式不再要求使用block\_on进行显式的
阻塞执行，但是，使用这种方式，要求启用async-std的特性
\footnote{关于async-std的特性说明：\url{https://docs.rs/async-std/1.9.0/async_std/\#features}}：
\begin{code-block}{toml}
[dependencies]
async-std = {version = "1.9.0", features = ["attributes"]}
\end{code-block}
只用启用了上述的特性，才可以如下进行使用：
\begin{code-block}{rust}
pub async fn async_hello() {
    info!("This is the async hello");
}

#[async_std::main]
async fn main() {
    async_hello().await;
}
\end{code-block}
上述方式相当于将main函数也当作一个异步函数，而该函数的执行，则是由async-std这个
运行时自己进行相关任务的调度。同样的，如果是在测试函数或者测试用例当中，也可以使用
这种方式：
\begin{code-block}{rust}
pub async fn async_hello() {
    info!("This is the async hello");
}

// 注意，同样需要启用attributes属性，并且，main需要修改为test
#[async_std::test]
async fn test_units() {
    async_hello().await;
}
\end{code-block}

如果是多个异步函数的执行，同样可以使用block\_on或者直接的await方式进行操作，但是，
需要注意的是，如果不加控制，不同的异步操作，默认情况下是串行执行的，比如下面的代码：
\begin{code-block}{rust}
use std::time::Duration;
use async_std;
pub async fn connect_db_fake() -> String {
    async_std::task::sleep(Duration::from_secs(1)).await;
    info!("This is the async connect_db_fake function");
    "connect_db_fake".to_owned()
}

pub async fn open_file_fake() -> String {
    async_std::task::sleep(Duration::from_secs(2)).await;
    info!("This is the async open_file_fake function");
    "open_file".to_owned()
}

fn main() {
    let db_fake = async_std::task::block_on(connect_db_fake());
    let file_fake = async_std::task::block_on(open_file_fake());
    ...
}
\end{code-block}
上述代码当中db\_fake和file\_fake并没有什么直接的关系，二者是完全可以并行执行的，
但是，实际的执行结果是，两行代码总计耗时3秒左右，并没有并行起来。如果想让这些
并没有关联关系的操作完全并行起来，则需要使用futures-rs提供的功能：
\begin{code-block}{toml}
[dependencies]
futures = "0.3.15"
async-std = {version = "1.9.0", features = ["attributes"]}
\end{code-block}
并行的代码修改如下：
\begin{code-block}{rust}
use futures;
fn main() {
    let now = time::Instant::now();
    let (fake_db, fake_file) =
        block_on(futures::future::join(connect_db_fake(), open_file_fake()));
    let elapsed = now.elapsed();
    assert_eq!("open_file", fake_file);
    assert_eq!("connect_db_fake", fake_db);
    println!("All of async function used {:#?} ", elapsed);
    assert!(elapsed > Duration::from_secs(1));
    assert!(elapsed < Duration::from_secs(3));
}
\end{code-block}
并行之后的代码，总体的执行时间取决于耗时最长的任务。当然，如果需要并行多个任务，
可以使用join2，join3，join4和join5等函数。针对常见的函数式编程，比如map-reduce
操作，则可以使用join\_all等方法：
\begin{code-block}{rust}
use futures::future::join_all;
use std::time::{self, Duration};
use std::sync::{Arc, Mutex};
use async_std;
pub async fn get_cities() -> Vec<String> {
    let cities = vec![
        "shanghai".to_owned(),
        "beijing".to_owned(),
        "chongqing".to_owned(),
    ];
    let city_vec = Arc::new(Mutex::new(vec![]));
    let _ = join_all(
        cities
            .into_iter()
            .map(|city| build_city(city_vec.clone(), city)),
    )
    .await;
    return city_vec.lock().unwrap().clone();
}

async fn build_city(city_vec: Arc<Mutex<Vec<String>>>, city: String) {
    async_std::task::sleep(Duration::from_secs(1)).await;
    city_vec
        .lock()
        .unwrap()
        .push(format!("Super City {}", city))
}

fn main() {
    let now = time::Instant::now();
    let res = block_on(get_cities());
    assert_eq!(
        vec![
            "Super City shanghai".to_owned(),
            "Super City beijing".to_owned(),
            "Super City chongqing".to_owned()
        ],
        res
    );
    let used = now.elapsed();
    assert!(used < Duration::from_secs(2));
}
\end{code-block}
注意，join\_all也是并行执行的，其耗费的时间同样取决于耗时最长的任务。

而如果只是需要并行任务当中的某一个或者某几个完成，则需要使用select操作：
\begin{code-block}{rust}
pub async fn fake_select_two() -> u8 {
    let future1 = async {
        // 该future一直是pending状态，永远不会返回
        future::pending::<()>().await;
        1
    };
    let future2 = async { future::ready(2).await };
    // 针对select操作，所有的future都必须使用pin_mut
    pin_mut!(future1);
    pin_mut!(future2);
    match future::select(future1, future2).await {
        // select返回（future的Output，另一个future）
        Either::Left((value1, _ignore_future)) => value1,
        Either::Right((value2, _ignore_future)) => value2,
    }
}
\end{code-block}

\begin{note}
Join，join\_all以及join系列的函数和join!这个宏，以及select函数和select!宏，都
包含在futures-rs这个类库当中（tokio当中也有），但是，这些函数以及宏定义，是兼容
目前所有的异步类库的。因此，可以在async-std以及tokio当中使用。
\end{note}

需要注意的是，异步任务（包括async-std、futures以及tokio等）通常是并行运行，但是
这个“并行”的基础是\colorblock{通过共享一个执行线程实现的}。这就意味着阻塞一个操作系统（std）
线程的操作，比如std::thread::sleep将停止所有共享该线程的任务的执行，无法和
async-std的并行模型很好的配合。因此，下列代码在执行过程当中，实际上是串行阻塞式
的运行的：
\begin{code-block}{rust}
task::block_on(async {
    // this is std::fs, which blocks
    std::fs::read_to_string("test_file");
})
\end{code-block}

针对文件系统的异步io，async-std提供了与std::fs兼容的async\_std::fs进行异步化：
\begin{code-block}{rust}
use async_std::fs::File;
use async_std::{io::{self, prelude::WriteExt}};
pub async fn async_file_opts() -> io::Result<()> {
    let mut file = File::create("a.txt").await?;
    Ok(file.write_all(b"hello world").await?)
}
\end{code-block}

同样是由于Rust的异步实现都是通过共享线程实现的，因此，必然会带来这样的问题：
有的异步任务属于定时任务，需要定期的执行，如果通过普通的sleep操作进行控制权
让出，必然会阻塞当前线程的运行，使得异步操作失败。针对这种问题，async-std提供
了自己的定时器解决方案，只不过，这个定时器方案需要启用async-std的unstable特性：
\begin{code-block}{rust}
[dependencies]
async-std = {version = "1.9.0", features = ["attributes", "unstable"]}
\end{code-block}
而代码则需要进行如下的变化：
\begin{code-block}{rust}
use std::time::Duration;
use async_std::stream::{self, StreamExt};

fn main() {
    // 生成一个定时器stream，用于定时发送提示
    let mut intvl = stream::interval(Duration::from_secs(1));
    let mut count = 0;
    // while let Some(_) = intvl.next().await {
    while let Some(_) = block_on(intvl.next()) {
        count += 1;
        if count > 5 {
            break;
        }
        println!("{} seconds elapsed ", count);
    }
}
\end{code-block}
通过在async-std的运行时内部利用stream实现一个定时器，可以很好的和当前线程进行
合理的分离，使得异步的定时任务成为可能。而在上面的代码当中，出现了一个关键字，
或者说是新的概念：stream。Stream实际上对应的是Rust当中迭代器的概念。在目前通用的
Rust异步编程类库当中，Stream的定义和实现上都是类似的，以futures-rs为例，其定义
大致如下\footnote{来源：\url{https://docs.rs/futures/0.3.16/futures/stream/trait.Stream.html}}
\begin{code-block}{rust}
pub trait Stream {

    type Item;

    fn poll_next(
        self: Pin<&mut Self>,
        cx: &mut Context<'_>
    ) -> Poll<Option<Self::Item>>;

    fn size_hint(&self) -> (usize, Option<usize>) { ... }
}
\end{code-block}
而async-std当中的Stream定义则稍微有些不同，不过，核心部分是类似的\footnote{async：\url{https://docs.rs/async-std/1.9.0/async_std/stream/trait.Stream.html}}：
\begin{code-block}{rust}
pub fn poll_next(
    self: Pin<&mut Self>,
    cx: &mut Context<'_>
) -> Poll<Option<Self::Item>>
\end{code-block}
并且，async-std也特意说明了，async-std当中的Stream实际上是对futures-rs当中的Stream的重新
导出（re-export），因此，二者在本质上并没有什么区别。和普通future相比，Stream在实现
上实际上并没有太大的区别，在编译器内部也是通过状态机或者生成器实现的。比如，一个
简单的Stream实现如下：
\begin{code-block}{rust}
use std::pin::Pin;

use async_std::prelude::*;
use async_std::stream;
use async_std::task::{Context, Poll};

fn increment(
    s: impl Stream<Item = i32> + Unpin,
) -> impl Stream<Item = i32> + Unpin {

    struct Increment<S>(S);

    impl<S: Stream<Item = i32> + Unpin> Stream for Increment<S> {

        type Item = S::Item;

        fn poll_next(
            mut self: Pin<&mut Self>,
            cx: &mut Context<'_>,
        ) -> Poll<Option<Self::Item>> {

            match Pin::new(&mut self.0).poll_next(cx) {
                Poll::Pending => Poll::Pending,
                Poll::Ready(None) => Poll::Ready(None),
                Poll::Ready(Some(item)) => Poll::Ready(Some(item + 1)),
            }
        }
    }

    Increment(s)
}

let mut s = increment(stream::once(7));
\end{code-block}
只不过，在真实的生产环境当中，stream的使用并没有这么复杂：
\begin{code-block}{rust}
// 下列2行任选其一即可
// use futures::stream::{self, StreamExt};
use async_std::stream::{self, StreamExt};

fn test_stream_future() {
    // futures-rs的用法
    //let mut streamf = stream::iter(1..=10);

    // async-std的用法
    let mut streamf = stream::from_iter(1..=10);

    let res = block_on(streamf.next());
    assert_eq!(Some(1), res);

    // 迭代器消费了一个元素
    let all_item = block_on(streamf.collect::<Vec<u8>>());
    assert_eq!(vec![2, 3, 4, 5, 6, 7, 8, 9, 10], all_item);
}
\end{code-block}
可以看到，futures-rs/async-std的stream和普通的迭代器基本没有太大的差别。而上面
的定时器，可以看作是async-std实现的一个stream特例。
\begin{critical}
默认情况下，针对有限的stream（即数据有限的迭代器），标准迭代器的所有方法都可以
使用，但是，针对无限的stream（即数据无限的迭代器），那些需要遍历所有stream当中
的元素的方法或者函数，则应当禁止使用，否则可能造成用于无法返回，比如下面的例子：
\begin{code-block}{rust}
// 构造一个无限的流，流当中的每个元素都是1
let ones = async_std::stream::repeat(1);
// 无法结束，因为min函数需要迭代流当中的所有元素
// 这是无法完成的操作
let least = ones.min().await.unwrap();
println!("The smallest number one is {}.", least);
\end{code-block}
\end{critical}

针对Rust常用的多线程通信方案channel，async-std以及futures-rs同样提供了对应的异步方案：
\begin{code-block}{rust}
use async_std::channel::{unbounded, RecvError, TryRecvError};
async fn test_async_channel() {
    let (sender, recver) = unbounded(); // 创建无缓冲的channel，如果是有缓冲
                                        // let (sender, recver) = bounded(2);
    assert_eq!(sender.send(1).await, Ok(()));
    assert_eq!(recver.recv().await, Ok(1));
    assert_eq!(recver.try_recv(), Err(TryRecvError::Empty));
    // 不管是unbounded还是bounded的channel，如果sender
    // 没有继续发送消息，也没有进行关闭，但是，继续使用
    // recver.recv() 操作，会导致对应的任务进入死锁状态
    // 无法继续向后执行，因此，下面的代码需要注意
    // assert_eq!(recver.recv().await, Ok(_));
    drop(sender);
    assert_eq!(recver.try_recv(), Err(TryRecvError::Closed));
    assert_eq!(recver.recv().await, Err(RecvError));
}
\end{code-block}
这些channel的使用方式和标准库当中的channel基本类似，唯一的区别可能就是他们是异步
方式。

\begin{note}
在async-std以及其他的异步执行器出来之前，使用最多的是future-rs。Future-rs提供了
Rust异步编程的所有完整实现，包括贡献了async/await关键字。不过，由于其他的异步执行器
发展比较快，生态比较完善，因此，相比较而言，future-rs使用并不是特别多。尤其是，
针对执行器，迭代器以及channel等的实现上，async-std以及tokio等都非常灵活和完善，
并且和future-rs的使用方式相兼容，因此，直接使用future-rs当作异步执行器并不是特别
常见，而是使用future-rs的其他功能。而async-std的目的是提供一个异步的Rust标准库（std）
的实现方案，在目前的版本当中，Rust的std方法，大部分都可以在\colorblock{async-std当中
找到对应的异步实现}，因此可以考虑在大多数的异步环境当中，直接使用async-std替换
对应的标准库。
\end{note}

\section{异步编程的实现方案-tokio}
\section{异步编程的实现方案-mio}

\section{优秀的并发-Crossbeam}
默认情况下，Rust标准库的多线程并发是非常安全和方便的，但是，也存在一些特殊情况，
会导致标准库的多线程使用起来受到诸多的限制，比如，在递归函数当中使用多线程：
\begin{code-block}{rust}
use std::thread;
const THRESHOLD: usize = 4;
// 由于Rust的跨线程通信的限制，要求input参数必须是static的生命周期
pub fn find_max(input: &'static [i32]) -> Option<i32> {
    if input.len() <= THRESHOLD {
        return input.iter().cloned().max();
    }
    let middle = input.len() / 2;
    let (left, right) = input.split_at(middle);
    // 由于thread限制，必须使用move关键字
    let thread_left = thread::spawn(move || find_max(left));
    let thread_right = thread::spawn(move || find_max(right));
    let max_left = thread_left.join().unwrap().unwrap();
    let max_right = thread_right.join().unwrap().unwrap();
    Some(max_left.max(max_right))
}
fn main() {
    static ARRAY_REF: &[i32] = &[12, 3, 45, 98, 100, 23, 878, 8765, 123, -897, 866666, 1241];
    let res = find_max(ARRAY_REF);
    info!("The res is {:?}", res);
}
\end{code-block}
由于诸多的限制，上述代码当中，如果需要对多个数组进行排序，则这些数组必须使用static
关键字进行标识，无法处理普通的数组，并且最终会导致生成的二进制文件比较大。

除此之外，比如Rust的通道，只存在多生产者单消费者这一种模式，这也并不符合现实生活
当中的多生产者多消费者的模型。为了改进Rust的并行/并发，目前大多数的开发者使用
Crossbeam\footnote{\url{https://github.com/crossbeam-rs/crossbeam}}替代标准库的thread，
比如，上述的递归函数当中使用多线程，就可以修改为如下的模式：
\begin{code-block}{rust}
extern crate crossbeam;
pub fn find_max_crossbeam(input: &[i32]) -> Option<i32> {
    if input.len() <= THRESHOLD {
        return input.iter().cloned().max();
    }
    let middle = input.len() / 2;
    let (left, right) = input.split_at(middle);
    crossbeam::scope(|s| {
        let thread_left = s.spawn(|_| find_max_crossbeam(left));
        let thread_right = s.spawn(|_| find_max_crossbeam(right));
        let max_left = thread_left.join().unwrap().unwrap();
        let max_right = thread_right.join().unwrap().unwrap();
        Some(max_left.max(max_right))
    })
    .unwrap()
}
fn main() {
    static ARRAY_REF: &[i32] = &[12, 3, 45, 98, 100, 23, 878, 8765, 123, -897, 866666, 1241];
    let res = short_lived::find_max_crossbeam(ARRAY_REF);
    info!("The res is {:?}", res);
    let array = [
        12, 3, 45, 98, 100, 23, 878, 8765, 123, -897, 866666, 12411234,
    ];
    let res = short_lived::find_max_crossbeam(&array);
    info!("The res is {:?}", res);
}
\end{code-block}
通过这样修改的函数，不管是针对static生命周期的还是普通生命周期的数据，都能够自如的处理。

同样的，也可以对Rust标准库的通道（Channel）进行优化，此时，则需要配合使用
\href{https://github.com/crossbeam-rs/crossbeam}{Crossbeam-Channel}。比如下面的例子：
启动2个并行的通道，一个通道负责消息的生产发送，一个通道负责消息的接收和处理。

\input{rust_part_8}
